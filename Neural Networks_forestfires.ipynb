{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "317e3108",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "tf.debugging.set_log_device_placement(False) \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf383b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating reproducible results from same code\n",
    "tf.random.set_seed(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b39e7d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  month  day  FFMC   DMC     DC  ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0   mar  fri  86.2  26.2   94.3  5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1   oct  tue  90.6  35.4  669.1  6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2   oct  sat  90.6  43.7  686.9  6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3   mar  fri  91.7  33.3   77.5  9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4   mar  sun  89.3  51.3  102.2  9.6  11.4  99   1.8   0.0  ...         0   \n",
       "\n",
       "   monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0         0         0         0         1         0         0         0   \n",
       "1         0         0         0         0         0         0         1   \n",
       "2         0         0         0         0         0         0         1   \n",
       "3         0         0         0         1         0         0         0   \n",
       "4         0         0         0         1         0         0         0   \n",
       "\n",
       "   monthsep  size_category  \n",
       "0         0          small  \n",
       "1         0          small  \n",
       "2         0          small  \n",
       "3         0          small  \n",
       "4         0          small  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest=pd.read_csv(r'C:\\Users\\tirgu\\Downloads\\forestfires.csv')\n",
    "forest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0301ccde",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c4e3751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = forest.copy() #Removing the dummies at this time\n",
    "df.drop(df.columns[11:30],axis=1,inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eabb624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   month          517 non-null    object \n",
      " 1   day            517 non-null    object \n",
      " 2   FFMC           517 non-null    float64\n",
      " 3   DMC            517 non-null    float64\n",
      " 4   DC             517 non-null    float64\n",
      " 5   ISI            517 non-null    float64\n",
      " 6   temp           517 non-null    float64\n",
      " 7   RH             517 non-null    int64  \n",
      " 8   wind           517 non-null    float64\n",
      " 9   rain           517 non-null    float64\n",
      " 10  area           517 non-null    float64\n",
      " 11  size_category  517 non-null    object \n",
      "dtypes: float64(8), int64(1), object(3)\n",
      "memory usage: 48.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56879995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month            0\n",
       "day              0\n",
       "FFMC             0\n",
       "DMC              0\n",
       "DC               0\n",
       "ISI              0\n",
       "temp             0\n",
       "RH               0\n",
       "wind             0\n",
       "rain             0\n",
       "area             0\n",
       "size_category    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "217b9b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aug    184\n",
       "sep    172\n",
       "mar     54\n",
       "jul     32\n",
       "feb     20\n",
       "jun     17\n",
       "oct     15\n",
       "apr      9\n",
       "dec      9\n",
       "jan      2\n",
       "may      2\n",
       "nov      1\n",
       "Name: month, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.month.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f84ce6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "small    378\n",
       "large    139\n",
       "Name: size_category, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # The dataset is biased. Lets remove the bias.\n",
    "df.size_category.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df0c3c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month  day  FFMC   DMC     DC  ISI  temp  RH  wind  rain  area  \\\n",
       "0      7    0  86.2  26.2   94.3  5.1   8.2  51   6.7   0.0   0.0   \n",
       "1     10    5  90.6  35.4  669.1  6.7  18.0  33   0.9   0.0   0.0   \n",
       "2     10    2  90.6  43.7  686.9  6.7  14.6  33   1.3   0.0   0.0   \n",
       "3      7    0  91.7  33.3   77.5  9.0   8.3  97   4.0   0.2   0.0   \n",
       "4      7    3  89.3  51.3  102.2  9.6  11.4  99   1.8   0.0   0.0   \n",
       "\n",
       "   size_category  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We are going to perform label encoding since it is faster than dummy variables\n",
    "\n",
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "df.month= label_encoder.fit_transform(df.month) \n",
    "df.day= label_encoder.fit_transform(df.day) \n",
    "df.size_category= label_encoder.fit_transform(df.size_category) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc63aa69",
   "metadata": {},
   "source": [
    "#  Remove bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c79753bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib as jb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39199c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 378, 0: 139})\n",
      "Counter({1: 372, 0: 372})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from collections import Counter\n",
    "\n",
    "resamp = df.copy()\n",
    "#SMOTEK TECHNIQUE\n",
    "\n",
    "#Define dataset\n",
    "a = resamp.iloc[:,:-1]\n",
    "b = resamp.iloc[:,-1]\n",
    "\n",
    "#Count before\n",
    "print(Counter(b))\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy = 'auto')\n",
    "a, b = smt.fit_resample(a, b)\n",
    "\n",
    "#Count after\n",
    "print(Counter(b)) #removed bias in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f514c8",
   "metadata": {},
   "source": [
    "#  Train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e123190",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = a\n",
    "Y = b\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023007a3",
   "metadata": {},
   "source": [
    "#  NNM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "757ca716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your first MLP in Keras\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49664227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "35/35 [==============================] - 1s 15ms/step - loss: 0.6906 - accuracy: 0.5201 - val_loss: 0.6834 - val_accuracy: 0.5988\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.6758 - accuracy: 0.6437 - val_loss: 0.6575 - val_accuracy: 0.8663\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.7557 - val_loss: 0.5933 - val_accuracy: 0.7791\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5520 - accuracy: 0.8046 - val_loss: 0.5149 - val_accuracy: 0.9884\n",
      "Epoch 5/50\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.8161 - val_loss: 0.4514 - val_accuracy: 0.7384\n",
      "Epoch 6/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3847 - accuracy: 0.8592 - val_loss: 0.3712 - val_accuracy: 0.7965\n",
      "Epoch 7/50\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3228 - accuracy: 0.9080 - val_loss: 0.3723 - val_accuracy: 0.8605\n",
      "Epoch 8/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2583 - accuracy: 0.9310 - val_loss: 0.2508 - val_accuracy: 0.9884\n",
      "Epoch 9/50\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2042 - accuracy: 0.9713 - val_loss: 0.1886 - val_accuracy: 0.9884\n",
      "Epoch 10/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1716 - accuracy: 0.9598 - val_loss: 0.2346 - val_accuracy: 0.8663\n",
      "Epoch 11/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1416 - accuracy: 0.9741 - val_loss: 0.1474 - val_accuracy: 0.9593\n",
      "Epoch 12/50\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1137 - accuracy: 0.9713 - val_loss: 0.1078 - val_accuracy: 0.9826\n",
      "Epoch 13/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0979 - accuracy: 0.9828 - val_loss: 0.0872 - val_accuracy: 0.9884\n",
      "Epoch 14/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1174 - accuracy: 0.9598 - val_loss: 0.0742 - val_accuracy: 0.9942\n",
      "Epoch 15/50\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1064 - accuracy: 0.9598 - val_loss: 0.0632 - val_accuracy: 0.9942\n",
      "Epoch 16/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0756 - accuracy: 0.9856 - val_loss: 0.0778 - val_accuracy: 0.9826\n",
      "Epoch 17/50\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.9741 - val_loss: 0.0545 - val_accuracy: 0.9942\n",
      "Epoch 18/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0863 - accuracy: 0.9655 - val_loss: 0.0490 - val_accuracy: 0.9942\n",
      "Epoch 19/50\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0589 - accuracy: 0.9914 - val_loss: 0.0447 - val_accuracy: 0.9884\n",
      "Epoch 20/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9914 - val_loss: 0.0411 - val_accuracy: 0.9942\n",
      "Epoch 21/50\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.9799 - val_loss: 0.0511 - val_accuracy: 0.9884\n",
      "Epoch 22/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.9914 - val_loss: 0.0365 - val_accuracy: 0.9942\n",
      "Epoch 23/50\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.9770 - val_loss: 0.0926 - val_accuracy: 0.9651\n",
      "Epoch 24/50\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0501 - accuracy: 0.9856 - val_loss: 0.2366 - val_accuracy: 0.8837\n",
      "Epoch 25/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.9713 - val_loss: 0.1596 - val_accuracy: 0.9419\n",
      "Epoch 26/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0727 - accuracy: 0.9598 - val_loss: 0.0695 - val_accuracy: 0.9767\n",
      "Epoch 27/50\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0417 - accuracy: 0.9856 - val_loss: 0.0344 - val_accuracy: 0.9884\n",
      "Epoch 28/50\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0538 - accuracy: 0.9799 - val_loss: 0.0372 - val_accuracy: 0.9942\n",
      "Epoch 29/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9713 - val_loss: 0.0283 - val_accuracy: 0.9942\n",
      "Epoch 30/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9770 - val_loss: 0.0282 - val_accuracy: 0.9884\n",
      "Epoch 31/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 0.9914 - val_loss: 0.0389 - val_accuracy: 0.9884\n",
      "Epoch 32/50\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0345 - accuracy: 0.9943 - val_loss: 0.0297 - val_accuracy: 0.9884\n",
      "Epoch 33/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0376 - accuracy: 0.9885 - val_loss: 0.0540 - val_accuracy: 0.9767\n",
      "Epoch 34/50\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0322 - accuracy: 0.9885 - val_loss: 0.0276 - val_accuracy: 0.9884\n",
      "Epoch 35/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0257 - accuracy: 0.9943 - val_loss: 0.0407 - val_accuracy: 0.9826\n",
      "Epoch 36/50\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9942\n",
      "Epoch 37/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9885 - val_loss: 0.1019 - val_accuracy: 0.9651\n",
      "Epoch 38/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0337 - accuracy: 0.9885 - val_loss: 0.0319 - val_accuracy: 0.9826\n",
      "Epoch 39/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0300 - accuracy: 0.9885 - val_loss: 0.0285 - val_accuracy: 0.9884\n",
      "Epoch 40/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.0295 - val_accuracy: 0.9884\n",
      "Epoch 41/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0238 - accuracy: 0.9971 - val_loss: 0.0273 - val_accuracy: 0.9942\n",
      "Epoch 42/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.9856 - val_loss: 0.0325 - val_accuracy: 0.9884\n",
      "Epoch 43/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 0.9943 - val_loss: 0.0278 - val_accuracy: 0.9884\n",
      "Epoch 44/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9770 - val_loss: 0.0368 - val_accuracy: 0.9942\n",
      "Epoch 45/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0424 - accuracy: 0.9828 - val_loss: 0.0465 - val_accuracy: 0.9767\n",
      "Epoch 46/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0331 - accuracy: 0.9828 - val_loss: 0.1910 - val_accuracy: 0.9360\n",
      "Epoch 47/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9828 - val_loss: 0.0318 - val_accuracy: 0.9884\n",
      "Epoch 48/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 0.9914 - val_loss: 0.0206 - val_accuracy: 0.9884\n",
      "Epoch 49/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 0.9971 - val_loss: 0.0463 - val_accuracy: 0.9767\n",
      "Epoch 50/50\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0241 - accuracy: 0.9914 - val_loss: 0.0322 - val_accuracy: 0.9826\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(14, input_dim=11, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(12,kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "hist = model.fit(X_train, y_train, validation_split=0.33, epochs=50, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52601b16",
   "metadata": {},
   "source": [
    "#  Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e497618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0272 - accuracy: 0.9866\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d4d43ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(hist.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbbbd5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.033062</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.190961</td>\n",
       "      <td>0.936047</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.045666</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.031812</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.021386</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.020585</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.021129</td>\n",
       "      <td>0.997126</td>\n",
       "      <td>0.046340</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.024076</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.032154</td>\n",
       "      <td>0.982558</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy  epoch\n",
       "45  0.033062  0.982759  0.190961      0.936047     45\n",
       "46  0.045666  0.982759  0.031812      0.988372     46\n",
       "47  0.021386  0.991379  0.020585      0.988372     47\n",
       "48  0.021129  0.997126  0.046340      0.976744     48\n",
       "49  0.024076  0.991379  0.032154      0.982558     49"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_df = pd.DataFrame(hist.history)\n",
    "hist_df[\"epoch\"]=hist.epoch\n",
    "hist_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983fc404",
   "metadata": {},
   "source": [
    "#  visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c32b3db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9d7b8e",
   "metadata": {},
   "source": [
    "# tunning hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5207b3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\tirgu\\anaconda3\\lib\\site-packages (2.8.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pacy (c:\\users\\tirgu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\tirgu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pacy (c:\\users\\tirgu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\tirgu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pacy (c:\\users\\tirgu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\tirgu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pacy (c:\\users\\tirgu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\tirgu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pacy (c:\\users\\tirgu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\tirgu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pacy (c:\\users\\tirgu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\tirgu\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b456bcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import adam_v2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b9052c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary packages\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import adam_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d9e25c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    \n",
    "    adam=Adam(lr=0.01)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb291046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "a = StandardScaler()\n",
    "a.fit(X)\n",
    "X_standardized = a.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbe93e8",
   "metadata": {},
   "source": [
    "# Tuning of Hyperparameters_Learning rate and Drop out rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "54e560e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
      "[CV 1/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.993 total time=   3.6s\n",
      "[CV 2/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
      "[CV 2/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.987 total time=   3.4s\n",
      "[CV 3/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
      "[CV 3/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.960 total time=   4.1s\n",
      "[CV 4/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
      "[CV 4/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.987 total time=   3.6s\n",
      "[CV 5/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
      "[CV 5/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=1.000 total time=   3.7s\n",
      "[CV 1/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
      "[CV 1/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.980 total time=   3.3s\n",
      "[CV 2/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
      "[CV 2/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.966 total time=   3.6s\n",
      "[CV 3/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
      "[CV 3/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.960 total time=   4.1s\n",
      "[CV 4/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
      "[CV 4/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.953 total time=   3.2s\n",
      "[CV 5/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
      "[CV 5/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.993 total time=   3.0s\n",
      "[CV 1/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
      "[CV 1/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.624 total time=   4.0s\n",
      "[CV 2/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
      "[CV 2/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.960 total time=   4.1s\n",
      "[CV 3/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
      "[CV 3/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.960 total time=   3.5s\n",
      "[CV 4/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
      "[CV 4/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.826 total time=   3.2s\n",
      "[CV 5/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
      "[CV 5/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.966 total time=   3.0s\n",
      "[CV 1/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
      "[CV 1/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=1.000 total time=   4.1s\n",
      "[CV 2/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
      "[CV 2/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.980 total time=   4.0s\n",
      "[CV 3/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
      "[CV 3/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.953 total time=   3.6s\n",
      "[CV 4/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
      "[CV 4/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.980 total time=   3.4s\n",
      "[CV 5/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
      "[CV 5/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.993 total time=   3.7s\n",
      "[CV 1/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
      "[CV 1/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.987 total time=   4.3s\n",
      "[CV 2/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
      "[CV 2/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.987 total time=   3.6s\n",
      "[CV 3/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
      "[CV 3/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.960 total time=   3.3s\n",
      "[CV 4/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
      "[CV 4/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.973 total time=   3.9s\n",
      "[CV 5/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
      "[CV 5/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.980 total time=   3.9s\n",
      "[CV 1/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
      "[CV 1/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.980 total time=   3.5s\n",
      "[CV 2/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
      "[CV 2/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.940 total time=   4.2s\n",
      "[CV 3/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
      "[CV 3/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.960 total time=   3.6s\n",
      "[CV 4/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
      "[CV 4/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.973 total time=   4.3s\n",
      "[CV 5/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
      "[CV 5/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.865 total time=   3.7s\n",
      "[CV 1/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
      "[CV 1/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=1.000 total time=   3.6s\n",
      "[CV 2/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
      "[CV 2/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.980 total time=   3.9s\n",
      "[CV 3/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
      "[CV 3/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.946 total time=   4.5s\n",
      "[CV 4/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
      "[CV 4/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.987 total time=   3.6s\n",
      "[CV 5/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
      "[CV 5/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.993 total time=   3.3s\n",
      "[CV 1/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
      "[CV 1/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=1.000 total time=   3.3s\n",
      "[CV 2/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
      "[CV 2/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.987 total time=   4.1s\n",
      "[CV 3/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
      "[CV 3/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.940 total time=   3.2s\n",
      "[CV 4/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
      "[CV 4/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.980 total time=   3.2s\n",
      "[CV 5/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
      "[CV 5/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.899 total time=   3.2s\n",
      "[CV 1/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
      "[CV 1/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=1.000 total time=   3.5s\n",
      "[CV 2/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
      "[CV 2/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.966 total time=   3.5s\n",
      "[CV 3/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
      "[CV 3/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.953 total time=   3.5s\n",
      "[CV 4/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
      "[CV 4/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.980 total time=   3.2s\n",
      "[CV 5/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
      "[CV 5/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.973 total time=   3.1s\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "# Defining the model\n",
    "\n",
    "def create_model2(learning_rate,dropout_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(14,input_dim = 11,kernel_initializer = 'uniform',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(12,input_dim = 14,kernel_initializer = 'uniform',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1,kernel_initializer='uniform',activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = learning_rate)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "\n",
    "model2 = KerasClassifier(build_fn = create_model2,verbose = 0,batch_size = 20,epochs = 50)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "learning_rate = [0.001,0.01,0.1]\n",
    "dropout_rate = [0.0,0.1,0.2]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids2 = dict(learning_rate = learning_rate,dropout_rate = dropout_rate)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid2 = GridSearchCV(estimator = model2,param_grid = param_grids2,cv = KFold(),verbose = 10)\n",
    "grid_result2 = grid2.fit(X_standardized,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19703720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.9852348804473877, using {'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
      "0.9852348804473877,0.013688649336326294 with: {'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
      "0.9704607248306274,0.014442500465630915 with: {'dropout_rate': 0.0, 'learning_rate': 0.01}\n",
      "0.8670687317848206,0.1324649552822729 with: {'dropout_rate': 0.0, 'learning_rate': 0.1}\n",
      "0.9811989903450012,0.016100577366465536 with: {'dropout_rate': 0.1, 'learning_rate': 0.001}\n",
      "0.9771539807319641,0.010037587693165345 with: {'dropout_rate': 0.1, 'learning_rate': 0.01}\n",
      "0.9434427738189697,0.041626938608565055 with: {'dropout_rate': 0.1, 'learning_rate': 0.1}\n",
      "0.9811989784240722,0.018689962849717325 with: {'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
      "0.960937774181366,0.03708600610744814 with: {'dropout_rate': 0.2, 'learning_rate': 0.01}\n",
      "0.9744603753089904,0.01554133523340404 with: {'dropout_rate': 0.2, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result2.best_score_,grid_result2.best_params_))\n",
    "means2 = grid_result2.cv_results_['mean_test_score']\n",
    "stds2 = grid_result2.cv_results_['std_test_score']\n",
    "params2 = grid_result2.cv_results_['params']\n",
    "for mean, stdev, param in zip(means2, stds2, params2):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))\n",
    "#Best score for Dropout rate = 0.2 and learning rate is 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b351dd7",
   "metadata": {},
   "source": [
    "# Tuning of Hyperparameters:- Activation Function and Kernel Initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3fbd3515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 1/5; 1/12] END activation_function=softmax, init=uniform;, score=0.027 total time=   4.0s\n",
      "[CV 2/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 2/5; 1/12] END activation_function=softmax, init=uniform;, score=0.711 total time=   4.5s\n",
      "[CV 3/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 3/5; 1/12] END activation_function=softmax, init=uniform;, score=0.389 total time=   4.1s\n",
      "[CV 4/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 4/5; 1/12] END activation_function=softmax, init=uniform;, score=0.483 total time=   4.0s\n",
      "[CV 5/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 5/5; 1/12] END activation_function=softmax, init=uniform;, score=0.000 total time=   4.0s\n",
      "[CV 1/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 1/5; 2/12] END activation_function=softmax, init=normal;, score=0.054 total time=   4.1s\n",
      "[CV 2/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 2/5; 2/12] END activation_function=softmax, init=normal;, score=0.718 total time=   3.8s\n",
      "[CV 3/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 3/5; 2/12] END activation_function=softmax, init=normal;, score=0.389 total time=   4.0s\n",
      "[CV 4/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 4/5; 2/12] END activation_function=softmax, init=normal;, score=0.503 total time=   3.5s\n",
      "[CV 5/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 5/5; 2/12] END activation_function=softmax, init=normal;, score=0.054 total time=   3.5s\n",
      "[CV 1/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 1/5; 3/12] END activation_function=softmax, init=zero;, score=0.000 total time=   4.2s\n",
      "[CV 2/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 2/5; 3/12] END activation_function=softmax, init=zero;, score=0.725 total time=   4.3s\n",
      "[CV 3/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 3/5; 3/12] END activation_function=softmax, init=zero;, score=0.362 total time=   3.9s\n",
      "[CV 4/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 4/5; 3/12] END activation_function=softmax, init=zero;, score=0.503 total time=   3.5s\n",
      "[CV 5/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 5/5; 3/12] END activation_function=softmax, init=zero;, score=0.000 total time=   3.7s\n",
      "[CV 1/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 1/5; 4/12] END activation_function=relu, init=uniform;, score=1.000 total time=   4.4s\n",
      "[CV 2/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 2/5; 4/12] END activation_function=relu, init=uniform;, score=0.980 total time=   3.3s\n",
      "[CV 3/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 3/5; 4/12] END activation_function=relu, init=uniform;, score=0.966 total time=   3.4s\n",
      "[CV 4/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 4/5; 4/12] END activation_function=relu, init=uniform;, score=0.993 total time=   3.9s\n",
      "[CV 5/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 5/5; 4/12] END activation_function=relu, init=uniform;, score=1.000 total time=   4.2s\n",
      "[CV 1/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 1/5; 5/12] END activation_function=relu, init=normal;, score=1.000 total time=   3.4s\n",
      "[CV 2/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 2/5; 5/12] END activation_function=relu, init=normal;, score=0.980 total time=   3.6s\n",
      "[CV 3/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 3/5; 5/12] END activation_function=relu, init=normal;, score=0.940 total time=   3.6s\n",
      "[CV 4/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 4/5; 5/12] END activation_function=relu, init=normal;, score=1.000 total time=   4.8s\n",
      "[CV 5/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 5/5; 5/12] END activation_function=relu, init=normal;, score=0.993 total time=   3.8s\n",
      "[CV 1/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 1/5; 6/12] END activation_function=relu, init=zero;, score=0.000 total time=   3.4s\n",
      "[CV 2/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 2/5; 6/12] END activation_function=relu, init=zero;, score=0.497 total time=   3.3s\n",
      "[CV 3/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 3/5; 6/12] END activation_function=relu, init=zero;, score=0.262 total time=   3.7s\n",
      "[CV 4/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 4/5; 6/12] END activation_function=relu, init=zero;, score=0.255 total time=   3.6s\n",
      "[CV 5/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 5/5; 6/12] END activation_function=relu, init=zero;, score=0.000 total time=   3.2s\n",
      "[CV 1/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 1/5; 7/12] END activation_function=tanh, init=uniform;, score=1.000 total time=   3.4s\n",
      "[CV 2/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 2/5; 7/12] END activation_function=tanh, init=uniform;, score=0.980 total time=   3.4s\n",
      "[CV 3/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 3/5; 7/12] END activation_function=tanh, init=uniform;, score=0.973 total time=   3.6s\n",
      "[CV 4/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 4/5; 7/12] END activation_function=tanh, init=uniform;, score=1.000 total time=   3.1s\n",
      "[CV 5/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 5/5; 7/12] END activation_function=tanh, init=uniform;, score=0.993 total time=   3.4s\n",
      "[CV 1/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 1/5; 8/12] END activation_function=tanh, init=normal;, score=1.000 total time=   3.2s\n",
      "[CV 2/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 2/5; 8/12] END activation_function=tanh, init=normal;, score=0.980 total time=   3.6s\n",
      "[CV 3/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 3/5; 8/12] END activation_function=tanh, init=normal;, score=0.973 total time=   3.4s\n",
      "[CV 4/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 4/5; 8/12] END activation_function=tanh, init=normal;, score=1.000 total time=   3.2s\n",
      "[CV 5/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 5/5; 8/12] END activation_function=tanh, init=normal;, score=1.000 total time=   3.5s\n",
      "[CV 1/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 1/5; 9/12] END activation_function=tanh, init=zero;, score=0.000 total time=   3.3s\n",
      "[CV 2/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 2/5; 9/12] END activation_function=tanh, init=zero;, score=0.497 total time=   4.0s\n",
      "[CV 3/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 3/5; 9/12] END activation_function=tanh, init=zero;, score=0.262 total time=   3.3s\n",
      "[CV 4/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 4/5; 9/12] END activation_function=tanh, init=zero;, score=0.255 total time=   3.3s\n",
      "[CV 5/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 5/5; 9/12] END activation_function=tanh, init=zero;, score=0.000 total time=   3.4s\n",
      "[CV 1/5; 10/12] START activation_function=linear, init=uniform..................\n",
      "[CV 1/5; 10/12] END activation_function=linear, init=uniform;, score=1.000 total time=   4.0s\n",
      "[CV 2/5; 10/12] START activation_function=linear, init=uniform..................\n",
      "[CV 2/5; 10/12] END activation_function=linear, init=uniform;, score=0.980 total time=   3.5s\n",
      "[CV 3/5; 10/12] START activation_function=linear, init=uniform..................\n",
      "[CV 3/5; 10/12] END activation_function=linear, init=uniform;, score=0.973 total time=   3.3s\n",
      "[CV 4/5; 10/12] START activation_function=linear, init=uniform..................\n",
      "[CV 4/5; 10/12] END activation_function=linear, init=uniform;, score=1.000 total time=   3.2s\n",
      "[CV 5/5; 10/12] START activation_function=linear, init=uniform..................\n",
      "[CV 5/5; 10/12] END activation_function=linear, init=uniform;, score=1.000 total time=   3.5s\n",
      "[CV 1/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 1/5; 11/12] END activation_function=linear, init=normal;, score=1.000 total time=   3.8s\n",
      "[CV 2/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 2/5; 11/12] END activation_function=linear, init=normal;, score=0.980 total time=   3.4s\n",
      "[CV 3/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 3/5; 11/12] END activation_function=linear, init=normal;, score=0.973 total time=   3.3s\n",
      "[CV 4/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 4/5; 11/12] END activation_function=linear, init=normal;, score=1.000 total time=   3.2s\n",
      "[CV 5/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 5/5; 11/12] END activation_function=linear, init=normal;, score=1.000 total time=   3.5s\n",
      "[CV 1/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 1/5; 12/12] END activation_function=linear, init=zero;, score=0.000 total time=   3.4s\n",
      "[CV 2/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 2/5; 12/12] END activation_function=linear, init=zero;, score=0.497 total time=   3.0s\n",
      "[CV 3/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 3/5; 12/12] END activation_function=linear, init=zero;, score=0.262 total time=   3.4s\n",
      "[CV 4/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 4/5; 12/12] END activation_function=linear, init=zero;, score=0.255 total time=   3.2s\n",
      "[CV 5/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 5/5; 12/12] END activation_function=linear, init=zero;, score=0.000 total time=   3.8s\n"
     ]
    }
   ],
   "source": [
    "# Defining the model\n",
    "\n",
    "def create_model3(activation_function,init):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(14,input_dim = 11,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(12,input_dim = 14,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "\n",
    "model3 = KerasClassifier(build_fn = create_model3,verbose = 0,batch_size = 20,epochs = 50)\n",
    "\n",
    "# Define the grid search parameters\n",
    "activation_function = ['softmax','relu','tanh','linear']\n",
    "init = ['uniform','normal','zero']\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grids3 = dict(activation_function = activation_function,init = init)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid3 = GridSearchCV(estimator = model3,param_grid = param_grids3,cv = KFold(),verbose = 10)\n",
    "grid_result3 = grid3.fit(X_standardized,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "03c7ecb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.9906040310859681, using {'activation_function': 'tanh', 'init': 'normal'}\n",
      "0.32214765027165415,0.2731139570648433 with: {'activation_function': 'softmax', 'init': 'uniform'}\n",
      "0.34369671568274496,0.25913571311168826 with: {'activation_function': 'softmax', 'init': 'normal'}\n",
      "0.3181208074092865,0.2842850387494907 with: {'activation_function': 'softmax', 'init': 'zero'}\n",
      "0.9879194617271423,0.013013905756522302 with: {'activation_function': 'relu', 'init': 'uniform'}\n",
      "0.9825412631034851,0.02269576260038635 with: {'activation_function': 'relu', 'init': 'normal'}\n",
      "0.20268456339836122,0.18697750311854777 with: {'activation_function': 'relu', 'init': 'zero'}\n",
      "0.9892526745796204,0.010901409006628766 with: {'activation_function': 'tanh', 'init': 'uniform'}\n",
      "0.9906040310859681,0.011701737826137155 with: {'activation_function': 'tanh', 'init': 'normal'}\n",
      "0.20268456339836122,0.18697750311854777 with: {'activation_function': 'tanh', 'init': 'zero'}\n",
      "0.9906040310859681,0.011701737826137155 with: {'activation_function': 'linear', 'init': 'uniform'}\n",
      "0.9906040310859681,0.011701737826137155 with: {'activation_function': 'linear', 'init': 'normal'}\n",
      "0.20268456339836122,0.18697750311854777 with: {'activation_function': 'linear', 'init': 'zero'}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result3.best_score_,grid_result3.best_params_))\n",
    "means3 = grid_result3.cv_results_['mean_test_score']\n",
    "stds3 = grid_result3.cv_results_['std_test_score']\n",
    "params3 = grid_result3.cv_results_['params']\n",
    "for mean, stdev, param in zip(means3, stds3, params3):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))\n",
    "#best activation function in our case would be Relu and Kernel Initializer is Uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12164d2",
   "metadata": {},
   "source": [
    "#  Tuning of Hyperparameter :-Number of Neurons in activation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "230158ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 1/5; 1/9] END .........neuron1=4, neuron2=4;, score=0.933 total time=   3.1s\n",
      "[CV 2/5; 1/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 2/5; 1/9] END .........neuron1=4, neuron2=4;, score=0.953 total time=   3.4s\n",
      "[CV 3/5; 1/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 3/5; 1/9] END .........neuron1=4, neuron2=4;, score=0.946 total time=   3.4s\n",
      "[CV 4/5; 1/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 4/5; 1/9] END .........neuron1=4, neuron2=4;, score=0.993 total time=   3.4s\n",
      "[CV 5/5; 1/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 5/5; 1/9] END .........neuron1=4, neuron2=4;, score=0.845 total time=   3.1s\n",
      "[CV 1/5; 2/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 1/5; 2/9] END .........neuron1=4, neuron2=8;, score=1.000 total time=   3.1s\n",
      "[CV 2/5; 2/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 2/5; 2/9] END .........neuron1=4, neuron2=8;, score=0.966 total time=   3.1s\n",
      "[CV 3/5; 2/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 3/5; 2/9] END .........neuron1=4, neuron2=8;, score=0.926 total time=   3.8s\n",
      "[CV 4/5; 2/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 4/5; 2/9] END .........neuron1=4, neuron2=8;, score=0.987 total time=   3.2s\n",
      "[CV 5/5; 2/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 5/5; 2/9] END .........neuron1=4, neuron2=8;, score=0.932 total time=   3.1s\n",
      "[CV 1/5; 3/9] START neuron1=4, neuron2=12.......................................\n",
      "[CV 1/5; 3/9] END ........neuron1=4, neuron2=12;, score=1.000 total time=   3.2s\n",
      "[CV 2/5; 3/9] START neuron1=4, neuron2=12.......................................\n",
      "[CV 2/5; 3/9] END ........neuron1=4, neuron2=12;, score=0.980 total time=   3.1s\n",
      "[CV 3/5; 3/9] START neuron1=4, neuron2=12.......................................\n",
      "[CV 3/5; 3/9] END ........neuron1=4, neuron2=12;, score=0.946 total time=   4.0s\n",
      "[CV 4/5; 3/9] START neuron1=4, neuron2=12.......................................\n",
      "[CV 4/5; 3/9] END ........neuron1=4, neuron2=12;, score=0.993 total time=   3.1s\n",
      "[CV 5/5; 3/9] START neuron1=4, neuron2=12.......................................\n",
      "[CV 5/5; 3/9] END ........neuron1=4, neuron2=12;, score=0.966 total time=   3.0s\n",
      "[CV 1/5; 4/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 1/5; 4/9] END .........neuron1=8, neuron2=4;, score=1.000 total time=   3.1s\n",
      "[CV 2/5; 4/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 2/5; 4/9] END .........neuron1=8, neuron2=4;, score=0.973 total time=   3.2s\n",
      "[CV 3/5; 4/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 3/5; 4/9] END .........neuron1=8, neuron2=4;, score=0.966 total time=   3.5s\n",
      "[CV 4/5; 4/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 4/5; 4/9] END .........neuron1=8, neuron2=4;, score=0.953 total time=   3.4s\n",
      "[CV 5/5; 4/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 5/5; 4/9] END .........neuron1=8, neuron2=4;, score=0.872 total time=   3.1s\n",
      "[CV 1/5; 5/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 1/5; 5/9] END .........neuron1=8, neuron2=8;, score=1.000 total time=   3.1s\n",
      "[CV 2/5; 5/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 2/5; 5/9] END .........neuron1=8, neuron2=8;, score=0.980 total time=   3.3s\n",
      "[CV 3/5; 5/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 3/5; 5/9] END .........neuron1=8, neuron2=8;, score=0.980 total time=   3.3s\n",
      "[CV 4/5; 5/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 4/5; 5/9] END .........neuron1=8, neuron2=8;, score=1.000 total time=   3.1s\n",
      "[CV 5/5; 5/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 5/5; 5/9] END .........neuron1=8, neuron2=8;, score=0.986 total time=   3.4s\n",
      "[CV 1/5; 6/9] START neuron1=8, neuron2=12.......................................\n",
      "[CV 1/5; 6/9] END ........neuron1=8, neuron2=12;, score=0.993 total time=   3.4s\n",
      "[CV 2/5; 6/9] START neuron1=8, neuron2=12.......................................\n",
      "[CV 2/5; 6/9] END ........neuron1=8, neuron2=12;, score=0.960 total time=   3.5s\n",
      "[CV 3/5; 6/9] START neuron1=8, neuron2=12.......................................\n",
      "[CV 3/5; 6/9] END ........neuron1=8, neuron2=12;, score=0.960 total time=   3.3s\n",
      "[CV 4/5; 6/9] START neuron1=8, neuron2=12.......................................\n",
      "[CV 4/5; 6/9] END ........neuron1=8, neuron2=12;, score=0.987 total time=   3.0s\n",
      "[CV 5/5; 6/9] START neuron1=8, neuron2=12.......................................\n",
      "[CV 5/5; 6/9] END ........neuron1=8, neuron2=12;, score=0.986 total time=   3.1s\n",
      "[CV 1/5; 7/9] START neuron1=14, neuron2=4.......................................\n",
      "[CV 1/5; 7/9] END ........neuron1=14, neuron2=4;, score=0.993 total time=   3.6s\n",
      "[CV 2/5; 7/9] START neuron1=14, neuron2=4.......................................\n",
      "[CV 2/5; 7/9] END ........neuron1=14, neuron2=4;, score=0.973 total time=   3.8s\n",
      "[CV 3/5; 7/9] START neuron1=14, neuron2=4.......................................\n",
      "[CV 3/5; 7/9] END ........neuron1=14, neuron2=4;, score=0.940 total time=   3.3s\n",
      "[CV 4/5; 7/9] START neuron1=14, neuron2=4.......................................\n",
      "[CV 4/5; 7/9] END ........neuron1=14, neuron2=4;, score=0.987 total time=   3.2s\n",
      "[CV 5/5; 7/9] START neuron1=14, neuron2=4.......................................\n",
      "[CV 5/5; 7/9] END ........neuron1=14, neuron2=4;, score=0.986 total time=   3.5s\n",
      "[CV 1/5; 8/9] START neuron1=14, neuron2=8.......................................\n",
      "[CV 1/5; 8/9] END ........neuron1=14, neuron2=8;, score=0.993 total time=   4.0s\n",
      "[CV 2/5; 8/9] START neuron1=14, neuron2=8.......................................\n",
      "[CV 2/5; 8/9] END ........neuron1=14, neuron2=8;, score=0.980 total time=   3.4s\n",
      "[CV 3/5; 8/9] START neuron1=14, neuron2=8.......................................\n",
      "[CV 3/5; 8/9] END ........neuron1=14, neuron2=8;, score=0.973 total time=   3.2s\n",
      "[CV 4/5; 8/9] START neuron1=14, neuron2=8.......................................\n",
      "[CV 4/5; 8/9] END ........neuron1=14, neuron2=8;, score=1.000 total time=   3.2s\n",
      "[CV 5/5; 8/9] START neuron1=14, neuron2=8.......................................\n",
      "[CV 5/5; 8/9] END ........neuron1=14, neuron2=8;, score=0.986 total time=   3.3s\n",
      "[CV 1/5; 9/9] START neuron1=14, neuron2=12......................................\n",
      "[CV 1/5; 9/9] END .......neuron1=14, neuron2=12;, score=1.000 total time=   4.2s\n",
      "[CV 2/5; 9/9] START neuron1=14, neuron2=12......................................\n",
      "[CV 2/5; 9/9] END .......neuron1=14, neuron2=12;, score=0.980 total time=   3.9s\n",
      "[CV 3/5; 9/9] START neuron1=14, neuron2=12......................................\n",
      "[CV 3/5; 9/9] END .......neuron1=14, neuron2=12;, score=0.966 total time=   3.5s\n",
      "[CV 4/5; 9/9] START neuron1=14, neuron2=12......................................\n",
      "[CV 4/5; 9/9] END .......neuron1=14, neuron2=12;, score=0.980 total time=   3.2s\n",
      "[CV 5/5; 9/9] START neuron1=14, neuron2=12......................................\n",
      "[CV 5/5; 9/9] END .......neuron1=14, neuron2=12;, score=1.000 total time=   3.8s\n"
     ]
    }
   ],
   "source": [
    "# Defining the model\n",
    "\n",
    "def create_model4(neuron1,neuron2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1,input_dim = 11,kernel_initializer = 'uniform',activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = 'uniform',activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "\n",
    "model4 = KerasClassifier(build_fn = create_model4,verbose = 0,batch_size = 20,epochs = 50)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "neuron1 = [4,8,14]\n",
    "neuron2 = [4,8,12]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids4 = dict(neuron1 = neuron1,neuron2 = neuron2)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid4 = GridSearchCV(estimator = model4,param_grid = param_grids4,cv = KFold(),verbose = 10)\n",
    "grid_result4 = grid4.fit(X_standardized,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9434f5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.9892436146736145, using {'neuron1': 8, 'neuron2': 8}\n",
      "0.9340195894241333,0.049036663395881974 with: {'neuron1': 4, 'neuron2': 4}\n",
      "0.9623254060745239,0.029068724987112476 with: {'neuron1': 4, 'neuron2': 8}\n",
      "0.9771358609199524,0.01929083884313707 with: {'neuron1': 4, 'neuron2': 12}\n",
      "0.9528478145599365,0.04340100999979232 with: {'neuron1': 8, 'neuron2': 4}\n",
      "0.9892436146736145,0.009109210451234305 with: {'neuron1': 8, 'neuron2': 8}\n",
      "0.9771630525588989,0.014445075950064265 with: {'neuron1': 8, 'neuron2': 12}\n",
      "0.975820779800415,0.019255288055963393 with: {'neuron1': 14, 'neuron2': 4}\n",
      "0.9865590453147888,0.009491430023727274 with: {'neuron1': 14, 'neuron2': 8}\n",
      "0.9852349042892456,0.013013905756522302 with: {'neuron1': 14, 'neuron2': 12}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result4.best_score_,grid_result4.best_params_))\n",
    "means4 = grid_result4.cv_results_['mean_test_score']\n",
    "stds4 = grid_result4.cv_results_['std_test_score']\n",
    "params4 = grid_result4.cv_results_['params']\n",
    "for mean, stdev, param in zip(means4, stds4, params4):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))\n",
    "\n",
    "#Best results are Neuron 1 = 4 and Neuron 2 = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f0a9f4",
   "metadata": {},
   "source": [
    "# Hyperparameters all at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d34a35c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[104   1]\n",
      " [  2 117]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       105\n",
      "           1       0.99      0.98      0.99       119\n",
      "\n",
      "    accuracy                           0.99       224\n",
      "   macro avg       0.99      0.99      0.99       224\n",
      "weighted avg       0.99      0.99      0.99       224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Defining the model\n",
    "\n",
    "def create_model_fnl():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(4,input_dim = 11,kernel_initializer = 'uniform',activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4,input_dim = 4,kernel_initializer = 'uniform',activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001) #sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model_fnl = KerasClassifier(build_fn = create_model_fnl,verbose = 0,batch_size = 20,epochs = 50)\n",
    "#Making training and Testing Data\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_standardized,Y, test_size = 0.3)\n",
    "# Fitting the model\n",
    "hist2 = model_fnl.fit(X_train_1,y_train_1)\n",
    "from sklearn.metrics import confusion_matrix,classification_report,plot_confusion_matrix\n",
    "def report_model(model):\n",
    "    model_preds = model.predict(X_test_1)\n",
    "    print(confusion_matrix(y_test_1,model_preds))\n",
    "    print(classification_report(y_test_1,model_preds))\n",
    "report_model(model_fnl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889bb667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b46fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ecb759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8167775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ce0e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
